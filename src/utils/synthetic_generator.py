"""
Synthetic Data Generator - Privacy Firewall
Generates privacy-preserving synthetic twins of real datasets
"""

import pandas as pd
import numpy as np
from typing import Dict, Tuple
import warnings
warnings.filterwarnings('ignore')


class SyntheticDataGenerator:
    """
    Creates synthetic dataset that preserves statistical properties
    but contains NO real patients (HIPAA-safe)
    """
    
    def __init__(self):
        self.metadata = {}
        self.real_stats = {}
    
    def fit(self, real_df: pd.DataFrame) -> None:
        """
        Learn statistical properties from real data
        Does NOT store actual patient records
        """
        print("ğŸ“Š Learning statistical properties from real data...")
        
        self.metadata = {
            'n_rows': len(real_df),
            'n_cols': len(real_df.columns),
            'columns': list(real_df.columns),
            'dtypes': real_df.dtypes.to_dict()
        }
        
        # Extract statistics only (no individual patients)
        for col in real_df.columns:
            if pd.api.types.is_numeric_dtype(real_df[col]):
                self.real_stats[col] = {
                    'type': 'numeric',
                    'mean': float(real_df[col].mean()),
                    'std': float(real_df[col].std()),
                    'min': float(real_df[col].min()),
                    'max': float(real_df[col].max()),
                    'median': float(real_df[col].median()),
                    'missing_rate': float(real_df[col].isna().mean())
                }
            else:
                value_counts = real_df[col].value_counts(normalize=True)
                self.real_stats[col] = {
                    'type': 'categorical',
                    'categories': value_counts.index.tolist(),
                    'probabilities': value_counts.values.tolist(),
                    'missing_rate': float(real_df[col].isna().mean())
                }
        
        print(f"  âœ“ Learned properties from {len(real_df)} real patients")
        print(f"  âœ“ Statistical metadata extracted (no patient data stored)")
    
    def generate(self, n_samples: int = None) -> pd.DataFrame:
        """
        Generate synthetic dataset with same statistical properties
        All patients are FAKE - HIPAA safe
        """
        if not self.real_stats:
            raise ValueError("Must call fit() before generate()")
        
        if n_samples is None:
            n_samples = self.metadata['n_rows']
        
        print(f"\nğŸ”„ Generating {n_samples} synthetic patients...")
        
        synthetic_data = {}
        
        for col, stats in self.real_stats.items():
            if stats['type'] == 'numeric':
                # Generate from normal distribution matching real data
                synthetic_values = np.random.normal(
                    loc=stats['mean'],
                    scale=stats['std'],
                    size=n_samples
                )
                
                # Clip to realistic range
                synthetic_values = np.clip(
                    synthetic_values,
                    stats['min'],
                    stats['max']
                )
                
                # Add missing values at same rate
                if stats['missing_rate'] > 0:
                    n_missing = int(n_samples * stats['missing_rate'])
                    missing_indices = np.random.choice(
                        n_samples,
                        size=n_missing,
                        replace=False
                    )
                    synthetic_values[missing_indices] = np.nan
                
                synthetic_data[col] = synthetic_values
            
            else:  # Categorical
                # Sample categories with same probabilities
                synthetic_values = np.random.choice(
                    stats['categories'],
                    size=n_samples,
                    p=stats['probabilities']
                )
                
                # Add missing values
                if stats['missing_rate'] > 0:
                    n_missing = int(n_samples * stats['missing_rate'])
                    missing_indices = np.random.choice(
                        n_samples,
                        size=n_missing,
                        replace=False
                    )
                    synthetic_values = synthetic_values.tolist()
                    for idx in missing_indices:
                        synthetic_values[idx] = np.nan
                
                synthetic_data[col] = synthetic_values
        
        synthetic_df = pd.DataFrame(synthetic_data)
        
        # Replace patient IDs with clearly synthetic ones
        if 'patient_id' in synthetic_df.columns:
            synthetic_df['patient_id'] = [f'SYNTH_{i:05d}' for i in range(1, n_samples + 1)]
        
        print(f"  âœ“ Generated {n_samples} synthetic patients")
        print(f"  âœ“ Preserved statistical properties")
        print(f"  âœ“ Zero real patients included")
        
        return synthetic_df
    
    def validate_privacy(self, real_df: pd.DataFrame, synthetic_df: pd.DataFrame) -> Dict:
        """
        Validate that synthetic data doesn't contain real patients
        """
        print("\nğŸ”’ Validating privacy preservation...")
        
        # Check 1: No exact matches
        exact_matches = 0
        for idx in range(min(100, len(real_df))):
            real_row = real_df.iloc[idx]
            matches = (synthetic_df == real_row).all(axis=1).sum()
            exact_matches += matches
        
        # Check 2: Statistical similarity
        stat_similarity = {}
        for col in real_df.select_dtypes(include=[np.number]).columns:
            real_mean = real_df[col].mean()
            synth_mean = synthetic_df[col].mean()
            similarity = 1 - abs(real_mean - synth_mean) / real_mean if real_mean != 0 else 0
            stat_similarity[col] = round(float(similarity), 3)
        
        avg_similarity = np.mean(list(stat_similarity.values()))
        
        privacy_score = 1.0 if exact_matches == 0 else 0.0
        
        print(f"  âœ“ Privacy score: {privacy_score} (0 exact matches found)")
        print(f"  âœ“ Statistical similarity: {avg_similarity:.1%}")
        
        return {
            'privacy_safe': exact_matches == 0,
            'exact_matches': exact_matches,
            'statistical_similarity': round(float(avg_similarity), 3),
            'ready_for_ai': exact_matches == 0 and avg_similarity > 0.7
        }


# Test if run directly
if __name__ == "__main__":
    print("=" * 60)
    print("Testing Synthetic Data Generator")
    print("=" * 60)
    
    # Load real dataset
    print("\nğŸ“‚ Loading real dataset...")
    real_df = pd.read_csv('data/synthetic/dataset2_diabetes_gender_bias.csv')
    print(f"   Real data: {len(real_df)} patients, {len(real_df.columns)} features")
    
    # Generate synthetic twin
    generator = SyntheticDataGenerator()
    generator.fit(real_df)
    
    synthetic_df = generator.generate(n_samples=1000)
    
    # Validate privacy
    validation = generator.validate_privacy(real_df, synthetic_df)
    
    # Compare distributions
    print("\nğŸ“Š Distribution Comparison:")
    print("\nGender distribution:")
    print("Real:     ", real_df['sex'].value_counts(normalize=True).to_dict())
    print("Synthetic:", synthetic_df['sex'].value_counts(normalize=True).to_dict())
    
    if 'age' in real_df.columns:
        print("\nAge statistics:")
        print(f"Real:      mean={real_df['age'].mean():.1f}, std={real_df['age'].std():.1f}")
        print(f"Synthetic: mean={synthetic_df['age'].mean():.1f}, std={synthetic_df['age'].std():.1f}")
    
    # Save synthetic
    output_path = 'data/synthetic/test_synthetic_twin.csv'
    synthetic_df.to_csv(output_path, index=False)
    print(f"\nâœ… Saved synthetic twin: {output_path}")
    
    if validation['ready_for_ai']:
        print("\nğŸ‰ Synthetic data is PRIVACY-SAFE and ready for AI analysis!")
    else:
        print("\nâš ï¸ Warning: Privacy or quality issues detected")
